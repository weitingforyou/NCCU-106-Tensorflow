{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "Agent learns to take actions maximizing expected reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/1/1b/Reinforcement_learning_diagram.svg)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The basic reinforcement is modeled as a Markov Decision Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Interpreter\n",
    "    * rules that describe what the agent observes\n",
    "* Environment\n",
    "    * The real world\n",
    "* Action\n",
    "    *  a set of actions, A, of the agent\n",
    "    * \n",
    "    <img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/5c19afafac92d3d0ee894b27ebea6b684c38ff5a' style='float:left; width:300px;height:100 px'/> \n",
    "    \n",
    "    is the probability of transition from state s to state s' under action a\n",
    "    \n",
    "    \n",
    "    \n",
    "* Agent\n",
    "    * The robot  \n",
    "* Reward\n",
    "    * <img src='https://wikimedia.org/api/rest_v1/media/math/render/svg/5f842d4a4b1340e194d8014d63163e5e27f94215' style='float:left;'/> is the immediate reward after transition from s to s' with action a\n",
    "    \n",
    "    \n",
    "* State\n",
    "    * a set of environment and agent states, S\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Formal notions\n",
    "\n",
    "* It’s not supervised learning, because the training data comes from the algorithm deciding between exploration and exploitation.  \n",
    "* It's not unsupervised because the algorithm receives feedback from the environment.  \n",
    "* Reinforcement learning : taking \"actions\" in \"situations\" to \"receive rewards\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Policy\n",
    "* The goal of reinforcement learning is to **discover a good strategy**.  \n",
    "* One of the most common ways to solve it is by observing the long-term consequences of actions at each state.  \n",
    "* Performing an action yields an immediate reward, but it’s not always a good idea to greedily choose the action with the best reward all the time.  \n",
    "* The best possible policy is called the **optimal policy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://i.imgur.com/REcxakc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Utility\n",
    "* The long-term reward is called a **utility**.  \n",
    "* The utility of performing an action **a** at a state **s** is written as a function **Q(s, a)**, called the utility function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://i.imgur.com/lDYnJ0q.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://i.imgur.com/ZPpFA6P.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* **s'** : the next state  \n",
    "* **a'** : the next action  \n",
    "* **r(s, a)** : the reward of taking action **a** in state **s**  \n",
    "* **γ** : the discount factor \n",
    "If γ is 0, then the agent chooses the action that maximizes the immediate reward.  \n",
    "Higher values of γ will make the agent put more importance in considering long-term consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![](https://i.imgur.com/BD0vddD.png)\n",
    "* **α** : the learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Alpha Go Example\n",
    "\n",
    "![](https://i.imgur.com/TGnInHi.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
